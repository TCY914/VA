[
  {
    "path": "posts/2022-06-04-takehome6/",
    "title": "Take-home Exercise 6",
    "description": "Practical Visual Analytics Use: VAST Challenge 2022, Challenge 1 - Social Network, exploring the significant patterns.",
    "author": [
      {
        "name": "Joyce Tseng",
        "url": "https://www.linkedin.com/in/joyce-tseng-a7115a1aa/"
      }
    ],
    "date": "2022-06-04",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Data Preparation\n2.1 Installing Packages\n2.2 Importing the Dataset\n2.3 Data Wrangling\n2.3.1 Prepare Overall Data\n2.3.2 Prepare Weekday Data\n2.3.3 Prepare Weekend Data\n\n\n3.Data Visualization\n3.1 Overall\n3.1.1\nSocial Relationship Between Participants with kids and Participants\nwithout kids\n3.1.2\nThe Distribution of Social Relationship on Weekday and Weekend\n\n3.2 Exploring\nsocial Butterflies on Weekdays\n3.3 Exploring\nSocial Butterflies on Weekends\n3.4 Who do\nthe top 10 influencers interact with?\n\n\n1. Overview\nIn this take-home exercise, we reveal the patterns of social\nactivities in Ohio, USA by creating data visualization with\nigraph and visNetwork.\nWith reference to Challenge 2 of VAST Challenge 2022,\nthe social patterns of community in Ohio, USA will be explored.\n2. Data Preparation\n2.1 Installing Packages\nThe following code chunk installs the required R packages and loads\nthem into RStudio environment. The loading packages for network\nvisualization are igraph, tidygraph,\nggraph,\nvisNetwork,\nwhile lubridate and tidyverse are packages for data\nwrangling.\n\n\nhide\n\npackages = c('igraph', 'tidygraph', 'ggraph', 'visNetwork', 'lubridate', 'tidyverse')\nfor(p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\n2.2 Importing the Dataset\nIn social network analysis, there are two main components required to\nplot a graph.\nNode Data: represent the source of entity,\nwhich refers to vertices in graph theory. In this take-home exercise,\nthe node data contains personal information of participants such as\ntheir age, household size, truth of having kids or not, education level\nand etc.\n\n\nhide\n\nParticipants <- read_csv(\"data/Participants.csv\")\n\n\n\nEdge Data: connect the node, which is also\ncalled links. In this take-home exercise, the edge data contains\ninformation on time and social activities between the participants.\n\n\nhide\n\nSocialNetwork <- read_csv(\"data/SocialNetwork.csv\")\n\n\n\n2.3 Data Wrangling\nThe following code chunk is to extract the needed data for the\nvisualization. In this exercise, we only use one month data from\n2022-03-01 to 2022-03-31. The columns in social network file are renamed\nfor better understanding. The weekdays() function is to\nfilter working days and non-working days.\n\n\nhide\n\nnodes <- Participants %>%\n  rename(\"id\" = \"participantId\") %>%\n  select(id, haveKids, joviality)\n\nedges <- SocialNetwork %>%\n  filter(timestamp < \"2022-04-01\") %>%\n  select(participantIdFrom, participantIdTo, timestamp) %>%\n  rename(\"source\" = \"participantIdFrom\", \"target\" = \"participantIdTo\") %>%\n  mutate(day = weekdays(timestamp)) %>%\n  mutate(daytype = case_when(day==\"Saturday\"|day==\"Sunday\" ~ 'Weekend',\n                             day==\"Monday\"|day==\"Tuesday\"|day==\"Wednesday\"\n                             |day==\"Thursday\"|day==\"Friday\" ~ 'Weekday'))\n\n\n\n2.3.1 Prepare Overall Data\nThe following code chuck is to filter and prepare the general data\nfor the later plot.\n\n\nhide\n\nx <- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\",\n       \"Saturday\", \"Sunday\")\n\ntotal_edges <- edges %>%\n  group_by(source, target, day) %>%\n  summarise(Weight = n()) %>%\n  mutate(day =  factor(day, levels = x)) %>%\n  arrange(day) %>%\n  filter(source!=target) %>%\n  filter(Weight > 2) %>%\n  ungroup\n\ntotal_edges <- total_edges %>%\n  left_join(y = nodes, by = c(\"source\" = \"id\"))\n\ntotal_nodes <- nodes %>% \n  filter(id %in% total_edges$source |\n         id %in% total_edges$target)\n\n\n\n\n\nhide\n\ntotal <- total_edges %>%\n  left_join(y = total_nodes, by = c(\"source\" = \"id\"))\n\n\n\n2.3.2 Prepare Weekday Data\nThe following code chuck is to filter and prepare the weekday data\nfor the later plot.\n\n\nhide\n\nedges_weekday <- edges %>%\n  filter(daytype == 'Weekday') %>%\n  group_by(source, target) %>%\n  summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 4) %>%\n  ungroup()\n\nnodes_weekday <- nodes %>% \n  filter(id %in% edges_weekday$source |\n         id %in% edges_weekday$target)\n\n\n\n2.3.3 Prepare Weekend Data\nThe following code chuck is to filter and prepare the weekend data\nfor the later plot.\n\n\nhide\n\nedges_weekend <- edges %>%\n  filter(daytype == 'Weekend') %>%\n  group_by(source, target) %>%\n  summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 4) %>%\n  ungroup()\n\nnodes_weekend <- nodes %>% \n  filter(id %in% edges_weekend$source |\n         id %in% edges_weekend$target)\n\n\n\n\n\nhide\n\nsaveRDS(edges, file = \"edges.rds\")\nsaveRDS(total_nodes, file = \"total_nodes.rds\")\nsaveRDS(total_edges, file = \"total_edges.rds\")\nsaveRDS(edges_weekday, file = \"edges_weekday.rds\")\nsaveRDS(nodes_weekday, file = \"nodes_weekday.rds\")\nsaveRDS(edges_weekend, file = \"edges_weekend.rds\")\nsaveRDS(nodes_weekend, file = \"nodes_weekend.rds\")\n\n\n\n\n\nhide\n\nedges <- readRDS(\"data/edges.rds\")\ntotal_nodes <- readRDS(\"data/total_nodes.rds\")\ntotal_edges <- readRDS(\"data/total_edges.rds\")\nedges_weekday <- readRDS(\"data/edges_weekday.rds\")\nnodes_weekday<- readRDS(\"data/nodes_weekday.rds\")\nedges_weekend <- readRDS(\"data/edges_weekend.rds\")\nnodes_weekend <- readRDS(\"data/nodes_weekend.rds\")\n\n\n\n3.Data Visualization\nTo create social network graph, igraph package is to\ncreate the prepared data for the following visualization.\ngraph_from_data_frame() of igraph is used to covert the nodes\nand edges data.frame into an igraph file format; while\nas_tbl_graph() of tidygraph() is used to convert the\nigraph file into tidygraph data model.\nBefore taking a look into the following plots, the following code\nchunk is to check the proportion of social interaction between weekday\nand weekend. It is surprising that the percentage of weekday is much\nhigher than weekend, which accounts for 26% of the total. The reason\nthat participants have more social activities on weekday might due to\ntheir social interactions in their workplaces.\n\n\nhide\n\noverall <- edges %>%\n  group_by(daytype) %>%\n  summarise(percent = n()/nrow(.))\n\noverall\n\n\n# A tibble: 2 × 2\n  daytype percent\n  <chr>     <dbl>\n1 Weekday   0.739\n2 Weekend   0.261\n\n3.1 Overall\n3.1.1\nSocial Relationship Between Participants with kids and Participants\nwithout kids\nIn this exercise, we would focus on the social interaction of\nparticipants with kids or without kids. We would like to explore whether\nhaving a kid would result in more social activities and expand their\nsocial network, since they may need to bring their child to the\nplayground or outdoor activities.\nThe first plot is to look at the comprehensive social relationship\nbetween each participant.\n\n\nhide\n\ngtotal <- graph_from_data_frame(total_edges,\n                               vertices = total_nodes) %>%\n  as_tbl_graph()\ngtotal\n\n\n# A tbl_graph: 877 nodes and 28678 edges\n#\n# A directed multigraph with 11 components\n#\n# Node Data: 877 × 3 (active)\n  name  haveKids joviality\n  <chr> <lgl>        <dbl>\n1 0     TRUE       0.00163\n2 1     TRUE       0.328  \n3 2     TRUE       0.393  \n4 3     TRUE       0.138  \n5 4     TRUE       0.857  \n6 5     TRUE       0.773  \n# … with 871 more rows\n#\n# Edge Data: 28,678 × 4\n   from    to day    Weight\n  <int> <int> <chr>   <int>\n1     1   219 Monday      3\n2     2    57 Monday      4\n3     2   744 Monday      4\n# … with 28,675 more rows\n\n\n\nhide\n\nset_graph_style() \ng <- ggraph(gtotal, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.8) +\n  scale_edge_width(range = c(1, 5)) +\n  geom_node_point(aes(colour = haveKids), \n                  size = 2,\n                  alpha=0.6)\ng + facet_edges(~day) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\nInsight From the graph\nThe above graphs do not clearly show the differences of social\nactivities between participants with kids and without kids on weekday\nand weekend. The pattern looks similar in each day. Therefore, to\nobserve the clear pattern, we would further plot the distribution of\nsocial relationship.\n3.1.2\nThe Distribution of Social Relationship on Weekday and Weekend\n\n\nhide\n\ng <- ggplot(data = fulltable, aes(x = Weekday, fill = haveKids)) +\n  geom_bar(position = \"dodge\") +  \n  labs(x=\"Weekday\", y=\"Count\", fill=\"Have Kids\") +\n  theme(axis.title.y= element_text(angle=0), \n        axis.line= element_line(color= 'grey'))\n\n\n\nInsight From the graph\nIt is interesting that the total of social activities on weekday is\nhigher, especially from Monday to Thursday. The highest count is showed\non Thursday. This might because that people would work more hardworking\non their jobs to communicate with their colleagues or customers in these\nfour days so as to ensure their tasks can be achieved on Friday and can\nbe relaxed on weekend. Therefore, there are more social\ninteractions.\nIn addition, family without kids has less activities. This might be\ndue to the fact that the number of participants with kid in the data is\nmuch less than people without kids. It is surprised that there are less\nsocial activities on weekend for people with kids. This may infer that\nparents pay more attention on their work on weekday and prefer to\nallocate their time with their children but not have activities with\nother friends.\n3.2 Exploring social\nButterflies on Weekdays\n\n\nhide\n\n#tbl_graph\ngweekday <- graph_from_data_frame(edges_weekday,\n                                  vertices = nodes_weekday) %>%\n  as_tbl_graph()\ngweekday\n\n\n# A tbl_graph: 878 nodes and 9084 edges\n#\n# A directed simple graph with 1 component\n#\n# Node Data: 878 × 3 (active)\n  name  haveKids joviality\n  <chr> <lgl>        <dbl>\n1 0     TRUE       0.00163\n2 1     TRUE       0.328  \n3 2     TRUE       0.393  \n4 3     TRUE       0.138  \n5 4     TRUE       0.857  \n6 5     TRUE       0.773  \n# … with 872 more rows\n#\n# Edge Data: 9,084 × 3\n   from    to Weight\n  <int> <int>  <int>\n1     1   220     11\n2     1   586     10\n3     2    58     19\n# … with 9,081 more rows\n\n\n\nhide\n\nquantile_gweekday <- quantile(eigen_centrality(gweekday)$vector,\n                           probs = seq(0, 1, 1/10))\n\nV(gweekday)$size = eigen_centrality(gweekday)$vector\n\ngweekday_aggregated <- delete_vertices(gweekday, \n                                       V(gweekday)[size < quantile_gweekday[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(gweekday_aggregated)\n\nquantile_gweekday_aggregated <- quantile(V(gweekday_aggregated)$size, \n                                         #identify top 10% of the new vertices\n                                        probs = seq(0, 1, 1/10))\n\n\nV(gweekday_aggregated)$color <- ifelse (V(gweekday_aggregated)$size > \n                                          quantile_gweekday_aggregated[10], \n                                        \"gold2\", \n                                        \"honeydew3\") #color yellow if vertices is top 10%\nE(gweekday_aggregated)$color <- \"grey\"\nV(gweekday_aggregated)$size <- V(gweekday_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(gweekday_aggregated)$label <- ifelse (V(gweekday_aggregated)$size*0.065 >\n                                          quantile_gweekday_aggregated[10],\n                                        V(gweekday_aggregated)$name,NA)\n#label the vertices if vertices belongs to the top 10%\n\nplot(gweekday_aggregated, edge.arrow.size=0.25,\n     edge.arrow.mode = \"-\", \n     vertex.label = V(gweekday_aggregated)$label, \n     vertex.label.cex = 0.65, \n     vertex.label.font = 2, \n     main = \"Which Participant has the most influence on weekdays?\") \n\n\n\n\nFrom the above graph, we can observe that there are 9 participants\nwho are regarded as a influential person based on their EigenVector\nScore, 686, 359, 460, 390, 255, 342, 478, 274, 398. To explore their\nsocial network circle, we would plot the interactive network graph in\nthe exercise later.\n3.3 Exploring Social\nButterflies on Weekends\n\n\nhide\n\n#tbl_graph\ngweekend <- graph_from_data_frame(edges_weekend,\n                                  vertices = nodes_weekend) %>%\n  as_tbl_graph()\ngweekend\n\n\n# A tbl_graph: 862 nodes and 4252 edges\n#\n# A directed simple graph with 7 components\n#\n# Node Data: 862 × 3 (active)\n  name  haveKids joviality\n  <chr> <lgl>        <dbl>\n1 0     TRUE       0.00163\n2 1     TRUE       0.328  \n3 2     TRUE       0.393  \n4 3     TRUE       0.138  \n5 4     TRUE       0.857  \n6 5     TRUE       0.773  \n# … with 856 more rows\n#\n# Edge Data: 4,252 × 3\n   from    to Weight\n  <int> <int>  <int>\n1     1   214      5\n2     1   575      5\n3     2    55      6\n# … with 4,249 more rows\n\n\n\nhide\n\nquantile_gweekend <- quantile(eigen_centrality(gweekend)$vector,\n                           probs = seq(0, 1, 1/10))\n\nV(gweekend)$size = eigen_centrality(gweekend)$vector\n\ngweekend_aggregated <- delete_vertices(gweekend, \n                                       V(gweekend)[size < quantile_gweekend[10]])\n\n\nset.seed (1234)\nlayout1 <- layout_with_fr(gweekend_aggregated)\n\nquantile_gweekend_aggregated <- quantile(V(gweekend_aggregated)$size, \n                                         #identify top 10% of the new vertices\n                                        probs = seq(0, 1, 1/10))\n\n\nV(gweekend_aggregated)$color <- ifelse(V(gweekend_aggregated)$size > \n                                          quantile_gweekend_aggregated[10], \n                                        \"gold2\", \n                                        \"honeydew3\") #color yellow if vertices is top 10%\nE(gweekend_aggregated)$color <- \"grey\"\nV(gweekend_aggregated)$size <- V(gweekend_aggregated)$size/0.065 \n#Increase the size of nodes based on their centrality score, only those with high score will be visible\n\nV(gweekend_aggregated)$label <- ifelse(V(gweekend_aggregated)$size*0.065 >\n                                          quantile_gweekend_aggregated[10],\n                                        V(gweekend_aggregated)$name,NA)\n#label the vertices if vertices belongs to the top 10%\n\nplot(gweekend_aggregated, edge.arrow.size=0.25,\n     edge.arrow.mode = \"-\", \n     vertex.label = V(gweekend_aggregated)$label, \n     vertex.label.cex = 0.65, \n     vertex.label.font = 2, \n     main = \"Which Participant has the most influence on weekends?\") \n\n\n\n\nFrom the above graph, it is interesting that 9 influential\nparticipants on weekend are different from weekday, which are 693, 417,\n613, 435, 258, 357, 447, 323, 450. This is owing to the fact that the\npurpose and property of social interactions on working days and\nnon-working days is not identical. On weekend, people may socialize more\non having entertainment, while on weekday, their social interactions\nmight be more relative to their work.\n3.4 Who do the top\n10 influencers interact with?\nSince the weekday have more social interactions on weekday, here we\ntake a closer look at the top 10 initiators and receivers within the\nparticipants.\nThe following code chunk is to find the top 10 initiator of the\nweekday social interactions.\n\n\nhide\n\ninitiation <- edges_weekday %>%\n  group_by(source) %>%\n  summarise(Initiation = sum(Weight)) %>%\n  arrange(desc(Initiation)) %>%\n  filter(row_number() <= 10)\n\ntop_initiation <- list(initiation$source)\n\n\n\nThe following code chunk is to find the top 10 receiver of the\nweekday social interactions.\n\n\nhide\n\nreceiver <- edges_weekday %>%\n  group_by(target) %>%\n  summarise(Receiving = sum(Weight)) %>%\n  arrange(desc(Receiving)) %>%\n  filter(row_number() <= 10)\n\ntop_receiver <- list(receiver$target)\n\n\n\nThe following result show that the top 10 initiator and receiver are\nsame.\n\n\nhide\n\ntop_initiation\n\n\n[[1]]\n [1]  390  835  679 1009  984  274  565  255  359  408\n\nhide\n\ntop_receiver\n\n\n[[1]]\n [1]  390  835  679 1009  984  274  565  255  359  408\n\nThe following code chunk prepares the data for the visualization and\nplot the network graph using vizNetwork()\n\n\nhide\n\nedges_weekday_most <- edges_weekday %>%\n  filter(source %in% initiation$source |\n         target %in% initiation$source)\n\nnodes_weekday_most <- nodes_weekday %>%\n  filter(id %in% edges_weekday_most$source |\n         id %in% edges_weekday_most$target)\n\n\n\n\n\nhide\n\nnodes_weekday_most <- nodes_weekday_most %>%\n  select(-c(joviality))\n\nedges_weekday_most <- edges_weekday_most %>%\n  rename(from = source,\n         to = target)\n\n\n\n\n\nhide\n\nnodes_weekday_most <- nodes_weekday_most %>%\n  rename(group = haveKids)\n\nvisNetwork(nodes_weekday_most,\n           edges_weekday_most, \n           main = \"Are you in the circles of the most socially active people?\",\n           submain = 'City of Engagement, Ohio, USA',\n           footer = 'Source: VAST Challenge 2022')%>%\n  visIgraphLayout(layout = 'layout_with_fr') %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 1234)\n\n\n\n\nInsight From the graph\nThe categorical label, True and False, in the plot is to identify\nparticipants with kid and without kids. By zooming in the graph and\nselecting particular participant Id, we are able to look at these 10\npeople’s social network closely. It is observed that people with kids\nhave more social interactions compared to those without kids.\n\n\n\n",
    "preview": "posts/2022-06-04-takehome6/takehome6_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2022-08-14T20:31:06+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-27-takehome5/",
    "title": "Take-home Exercise 5",
    "description": "Practical Visual Analytics Use: VAST Challenge 2022, Challenge 2 - Pattern of Life, focusing on map of social areas and locations with traffic bottleneck.",
    "author": [
      {
        "name": "Joyce Tseng",
        "url": "https://www.linkedin.com/in/joyce-tseng-a7115a1aa/"
      }
    ],
    "date": "2022-05-29",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Data Preparation\n2.1 Installing Packages\n2.2 Importing the Dataset\n2.3 Data Wrangling\n2.3.1 Traffic\nBottleneck on Recreation Areas\n2.3.2 Traffic\nBottleneck on Commute Areas\n\n2.3.3 Movement Path\n\n3. Data Visualizations\nand Insights\n3.1 Social Areas\n3.1.1 Social Areas\nin Residential Districts\n3.1.2 Social Areas in\nWorkplaces\n\n3.2 Traffic\nBottleneck on Recreation Areas\n3.2.1 Weekday Recreation\n3.2.1 Weekend Recreation\n\n3.2 Traffic\nBottleneck on Commute Areas\n3.2.1 Weekday Commute\n3.2.1 Weekdend Commute\n\n3.3 Movement Path\n3.3.1 Movement of\nMost Happiness Participants\n3.3.1 Movement\nof Least Happiness Participants\n\n\n4. Learning Points\n\n1. Overview\nIn this take-home exercise, we reveal the patterns of life in Ohio,\nUSA by creating data visualization with tmap.\nWith reference to point 1 and 2 in Challenge 2 of VAST Challenge 2022,\nthe following questions will be addressed:\nAssuming the volunteers are representative of the city’s\npopulation, characterize the social areas of the city that you\nidentify.\nWhere are the busiest areas in Engagement? Are there traffic\nbottlenecks that should be addressed?\n2. Data Preparation\n2.1 Installing Packages\nThe following code chunk installs the required R packages and loads\nthem into RStudio environment.\n\n\npackages = c('sf', 'tmap', 'tidyverse', 'lubridate', 'clock',\n             'sftime', 'rmarkdown', 'dplyr')\n\nfor(p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\n2.2 Importing the Dataset\nRelevant datasets are imported using read_sf() of sf\npackage, which designs to handle, process, visualise and analyse\nmovement or geospatial data.\n\n\nbuildings <- read_sf(\"data/Buildings.csv\", \n                   options = \"GEOM_POSSIBLE_NAMES=location\")\n\nemployers <- read_sf(\"data/Employers.csv\", \n                   options = \"GEOM_POSSIBLE_NAMES=location\")\n\npubs <- read_sf(\"data/Pubs.csv\", \n                   options = \"GEOM_POSSIBLE_NAMES=location\")\n\nrestaurants <- read_sf(\"data/Restaurants.csv\", \n                   options = \"GEOM_POSSIBLE_NAMES=location\")\n\napartments <- read_sf(\"data/Apartments.csv\", \n                   options = \"GEOM_POSSIBLE_NAMES=location\")\n\n\n\n2.3 Data Wrangling\nTo observe residents’ movement in Ohio everyday, we import an\nadditional data, TravelJournal, for the following visualizations. The\nvisualization of traffic bottleneck would divide into recreation and\ncommute area. Followed by this, we would reveal the movement path of\nresidents with the highest and lowest joviality to see the differences\nof their daily patterns.\n2.3.1 Traffic Bottleneck\non Recreation Areas\nIMPORT TRAVEL JOURNAL\n\n\ntravel <- read_csv(\"data/TravelJournal.csv\") %>%\n  mutate(travelEndLocationId = as.character(travelEndLocationId),\n         travelStartLocationId = as.character(travelStartLocationId))\n\n\n\nFILTER RECREATION PURPOSE\n\n\ntravel1 <- travel %>%\n  filter(purpose == \"Recreation (Social Gathering)\")\n\ntravel2 <- travel %>%\n  filter(purpose == \"Coming Back From Restaurant\")\n\n\n\nCREATE LOCATION POINTS DATA\n\n\nrestaurants_location <- restaurants %>%\n  select(restaurantId, location, buildingId) %>%\n  rename(\"locationId\" = \"restaurantId\")\n\npubs_location <- pubs %>%\n  select(pubId, location, buildingId) %>%\n  rename(\"locationId\" = \"pubId\")\n\napartments_location <- apartments %>%\n  select(apartmentId, location, buildingId) %>%\n  rename(\"locationId\" = \"apartmentId\")\n\nemployers_location <- employers %>%\n  select(employerId, location, buildingId) %>%\n  rename(\"locationId\" = \"employerId\")\n\nsocial_area <- rbind(restaurants_location, \n                     pubs_location, \n                     apartments_location, \n                     employers_location)\n\n\n\nJOIN LOCATION COLUMN\n\n\ntravel1 <- social_area %>%\n  inner_join(travel1, by = c(\"locationId\" = \"travelEndLocationId\")) %>%\n  rename(\"travelEndLocationId\" = \"locationId\")\n\ntravel2 <- social_area %>%\n  inner_join(travel2, by = c(\"locationId\" = \"travelStartLocationId\")) %>%\n  rename(\"travelStartLocationId\" = \"locationId\")\n\ntravel1 <- travel1[, c(4,5,6,7,1,8,9,10,11,12,2,3)]\ntravel2 <- travel2[, c(4,5,1,6,7,8,9,10,11,12,2,3)]\n\nrecreation <- rbind(travel1, travel2)\n\n\n\nDROP USELESS COLUMNS\n\n\nrecreation <- recreation %>%\n  select(-c(checkInTime, checkOutTime, startingBalance, endingBalance, \n            travelEndTime, buildingId, purpose))\n\n\n\n\n\n\n\n\n\nDERIVE TIME FIELDS\n\n\nrecreation <- recreation %>%\n  mutate(date = as.Date(travelStartTime)) %>%\n  mutate(day = weekdays(date)) %>%\n  mutate(days = get_day(travelStartTime)) \n\n\n\nFILTER WEEKDAY & WEEKEND\n\n\nrecreation_weekday <- recreation %>%\n  filter(day == \"Monday\" | day == \"Tuesday\" | day == \"Wednesday\" |\n           day == \"Thursday\" | day == \"Friday\")\n\nrecreation_weekend <- recreation %>%\n  filter(day == \"Saturday\" | day == \"Sunday\")\n\n\n\n2.3.2 Traffic Bottleneck on\nCommute Areas\nFILTER COMMUTE PURPOSE\n\n\ntravel3 <- travel %>%\n  filter(purpose == \"Work/Home Commute\")\n\n\n\nJOIN LOCATION COLUMN\n\n\ntravel3 <- social_area %>%\n  inner_join(travel3, by = c(\"locationId\" = \"travelEndLocationId\")) %>%\n  rename(\"travelEndLocationId\" = \"locationId\")\n\ntravel3 <- travel3[, c(4,5,6,7,1,8,9,10,11,12,2,3)]\n\n\n\nDROP USELESS COLUMNS\n\n\ntravel3 <- travel3 %>%\n  select(-c(checkInTime, checkOutTime, startingBalance, endingBalance, \n            travelEndTime, buildingId, purpose))\n\n\n\n\n\n\n\n\n\nDERIVE TIME FIELD\n\n\ncommute <- commute %>%\n  mutate(date = as.Date(travelStartTime)) %>%\n  mutate(day = weekdays(date)) %>%\n  mutate(days = get_day(travelStartTime)) \n\n\n\nFILTER WEEKDAY & WEEKEND\n\n\ncommute_weekday <- commute %>%\n  filter(day == \"Monday\" | day == \"Tuesday\" | day == \"Wednesday\" |\n           day == \"Thursday\" | day == \"Friday\")\n\ncommute_weekend <- commute %>%\n  filter(day == \"Saturday\" | day == \"Sunday\")\n\n\n\n2.3.3 Movement Path\nJOIN LOCATION COLUMN\n\n\nmovement <- social_area %>%\n  inner_join(movement, by = c(\"locationId\" = \"travelEndLocationId\")) %>%\n  rename(\"travelEndLocationId\" = \"locationId\")\n\nmovement <- movement[, c(4,5,6,7,1,8,9,10,11,12,2,3)]\n\n\n\n\n\n\n\n\n\nDERIVE TIME FIELD\n\n\nmove_path <- movement %>%\n  mutate(date = as.Date(travelStartTime)) %>%\n  mutate(day = weekdays(date)) %>%\n  mutate(days = get_day(travelStartTime)) \n\n\n\nFILTER PARTICIPANTS WITH HIGHEST AND LOWEST\nJOVIALITY\n\n\nmove_path <- move_path %>% \n  filter(participantId == \"758\" | participantId == \"131\") \n\n\n\n\n\n\n\n\n\n3. Data Visualizations and\nInsights\n3.1 Social Areas\n3.1.1 Social Areas in\nResidential Districts\nBlue dot: Residential Districts\nRed dot: Restaurants\nYellow dot: Pubs\n\n\ntmap_mode(\"plot\")\ntm_shape(buildings) +\ntm_polygons(col = \"grey60\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1) +\ntm_shape(apartments) +\n  tm_dots(col = \"#4682B4\", size = 0.3, alpha= 0.8) +\ntm_shape(pubs) +\n  tm_dots(col = \"#FFD700\", size = 0.5) +\ntm_shape(restaurants) +\n  tm_dots(col = \"#DC143C\", size = 0.5)\n\n\n\n\n3.1.2 Social Areas in\nWorkplaces\nGreen dot: Workplaces\nRed dot: Restaurants\nYellow dot: Pubs\n\n\ntmap_mode(\"plot\")\ntm_shape(buildings)+\ntm_polygons(col = \"grey60\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1) +\ntm_shape(employers) +\n  tm_dots(col = \"#2E8B57\", size = 0.5) +\ntm_shape(pubs) +\n  tm_dots(col = \"#FFD700\", size = 0.5) +\ntm_shape(restaurants) +\n  tm_dots(col = \"#DC143C\", size = 0.5)\n\n\n\n\nInsights\nCompared to the distance between residential and recreation places,\nthe location of workplaces has more overlapped areas. This is probably\nfor office workers to release their pressure after work without moving a\nlong distance to the recreational merchants.\n3.2 Traffic Bottleneck\non Recreation Areas\nCOMPUTE HEXAGONS\nTo plot hexagon binning maps, we need to compute and create hexagons\nfirst.\n\n\nhex <- st_make_grid(buildings, \n                    cellsize=100, \n                    square=FALSE) %>%\n  st_sf() %>%\n  rowid_to_column('hex_id')\n\n\n\n3.2.1 Weekday Recreation\nCOUNT EVENT POINTS\n\n\nweekday_points <- st_join(recreation_weekday, \n                          hex, \n                          join = st_within) %>%\n  st_set_geometry(NULL) %>%\n  count(name ='pointCount', hex_id)\n\nhead(weekday_points)\n\n\n# A tibble: 6 × 2\n  hex_id pointCount\n   <int>      <int>\n1    641       6706\n2    775      12388\n3    815      28020\n4    863      13217\n5   1004      13824\n6   1179       4834\n\nPERFORM RELATIONAL JOIN\n\n\nhex_weekday <- hex %>%\n  left_join(weekday_points, \n            by = 'hex_id') %>%\n  replace(is.na(.), 0)\n\n\n\nVISUALISATION\n\n\ntmap_mode(\"view\")\ntm_shape(hex_weekday %>%\n           filter(pointCount > 0))+\n  tm_fill(\"pointCount\",\n          n = 8,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.1)\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n3.2.1 Weekend Recreation\nCOUNT EVENT POINTS\n\n\nweekend_points <- st_join(recreation_weekend, \n                          hex, \n                          join = st_within) %>%\n  st_set_geometry(NULL) %>%\n  count(name ='pointCount', hex_id)\n\nhead(weekend_points)\n\n\n# A tibble: 6 × 2\n  hex_id pointCount\n   <int>      <int>\n1    641       8613\n2    775       3515\n3    815      10684\n4    863      13852\n5   1004      14982\n6   1179       1362\n\nPERFORM RELATIONAL JOIN\n\n\nhex_weekend <- hex %>%\n  left_join(weekend_points, \n            by = 'hex_id') %>%\n  replace(is.na(.), 0)\n\n\n\nVISUALISATION\n\n\ntmap_mode(\"view\")\ntm_shape(hex_weekend %>%\n           filter(pointCount > 0))+\n  tm_fill(\"pointCount\",\n          n = 8,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.1)\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\nInsights\nThe popular places in recreation areas on weekend and weekday are\ndifferent. In addition, it is also interesting that the event points on\nweekday are slightly more than point on weekend, meaning that people are\nmore frequent to entertain in social areas after work.\n3.2 Traffic Bottleneck on\nCommute Areas\n3.2.1 Weekday Commute\nCOUNT EVENT POINTS\n\n\ncweekday_points <- st_join(commute_weekday, \n                          hex, \n                          join = st_within) %>%\n  st_set_geometry(NULL) %>%\n  count(name ='pointCount', hex_id)\n\nhead(cweekday_points)\n\n\n# A tibble: 6 × 2\n  hex_id pointCount\n   <int>      <int>\n1    169        257\n2    212        964\n3    225        194\n4    226       2119\n5    227        642\n6    228        964\n\nPERFORM RELATIONAL JOIN\n\n\nhex_cweekday <- hex %>%\n  left_join(cweekday_points, \n            by = 'hex_id') %>%\n  replace(is.na(.), 0)\n\n\n\nVISUALISATION\n\n\ntmap_mode(\"view\")\ntm_shape(hex_cweekday %>%\n           filter(pointCount > 0))+\n  tm_fill(\"pointCount\",\n          n = 8,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.1)\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n3.2.1 Weekdend Commute\nCOUNT EVENT POINTS\n\n\ncweekend_points <- st_join(commute_weekend, \n                          hex, \n                          join = st_within) %>%\n  st_set_geometry(NULL) %>%\n  count(name ='pointCount', hex_id)\n\nhead(cweekend_points)\n\n\n# A tibble: 6 × 2\n  hex_id pointCount\n   <int>      <int>\n1    169         64\n2    225        128\n3    226        128\n4    260        128\n5    272        128\n6    273         64\n\nPERFORM RELATIONAL JOIN\n\n\nhex_cweekend <- hex %>%\n  left_join(cweekend_points, \n            by = 'hex_id') %>%\n  replace(is.na(.), 0)\n\n\n\nVISUALISATION\n\n\ntmap_mode(\"view\")\ntm_shape(hex_cweekend %>%\n           filter(pointCount > 0))+\n  tm_fill(\"pointCount\",\n          n = 8,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.1)\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\nInsights\nFrom the above two graphs, it can obviously be observed that the\nissue of traffic congestion is more serious from Monday to Friday.\nCrowds of people head to those places, which leads to more\ntransportation issues in the city and have to be addressed by the\ngovernment.\n3.3 Movement Path\nCREATE MOVEMENT PATH FROM EVENT POINTS\n\n\npath <- move_path %>%\n  group_by(participantId, day) %>%\n  summarize(m = mean(travelStartTime), \n            do_union=FALSE) %>%\n  st_cast(\"LINESTRING\")\n\n\n\n3.3.1 Movement of Most\nHappiness Participants\nBlue dot: Residential Districts\nGreen dot: Workplaces\nRed dot: Restaurants\nYellow dot: Pubs\n\n\npath_758 <- path %>%\n  filter(participantId == 758)\n\ntm_shape(buildings)+\ntm_polygons(col = \"grey60\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1) +\ntm_shape(path_758) +\n  tm_lines(col = '#ffa500',\n           scale = 3) +\ntm_shape(apartments) +\n  tm_dots(col = \"#4682B4\", size = 0.3, alpha= 0.8) +\ntm_shape(employers) +\n  tm_dots(col = \"#2E8B57\", size = 0.5) +\ntm_shape(pubs) +\n  tm_dots(col = \"#FFD700\", size = 0.5) +\ntm_shape(restaurants) +\n  tm_dots(col = \"#DC143C\", size = 0.5)\n\n\n\n\n3.3.1 Movement of\nLeast Happiness Participants\nBlue dot: Residential Districts\nGreen dot: Workplaces\nRed dot: Restaurants\nYellow dot: Pubs\n\n\npath_131 <- path %>%\n  filter(participantId == 131)\n\ntm_shape(buildings)+\ntm_polygons(col = \"grey60\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1) +\ntm_shape(path_131) +\n  tm_lines(col = '#ffa500',\n           scale = 3) +\ntm_shape(apartments) +\n  tm_dots(col = \"#4682B4\", size = 0.3, alpha= 0.8) +\ntm_shape(employers) +\n  tm_dots(col = \"#2E8B57\", size = 0.5) +\ntm_shape(pubs) +\n  tm_dots(col = \"#FFD700\", size = 0.5) +\ntm_shape(restaurants) +\n  tm_dots(col = \"#DC143C\", size = 0.5)\n\n\n\n\nInsights\nThere is no intersection of the most and least happiness participants\nin Ohio in the social cycle. Participant id = 758 with the highest\njoviality mainly has activities in the northwest of the city, while\nparticipant id = 131 with the lowest joviality activate in the east of\nsouth. In addition, participant id = 758 are more common to go to\nrestaurants and pubs.\n4. Learning Points\nThis take-home exercise helps us to understand how to plot\nvisualizations for maps and geospatial data. Furthermore, it also makes\nme learn a new package in R for plotting a graph, `tmap``.\nMy key takeaways are:\nThe types of spatial objects would influence the design of\ngraphs. Thus, it is necessary for us to print and read the data to check\nthe spatial objects before creating the visualization. In addition, the\ntype of spatial objects can only be converted from bigger objects to\nsmaller objects but cannot convert reversely. For example, it is\nfeasible to convert objects from polygons to lines or points, but it not\nviable to obtain lines or polygons from points.\nIt is always better to use the installed packages to clean data\nsuch as tidyverse and dplyr instead of using\nbuilt-in function in R, since those functions are not always applicable\nto all data types in R. To achieve our data preparation process, we need\nto take more notice on picking the right function in our code.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-08-14T20:31:06+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-19-takehome4/",
    "title": "Take-home Exercise 4",
    "description": "This is my Take-home Exercise to reveal the daily routine of two residents in Ohio, USA.",
    "author": [
      {
        "name": "Joyce Tseng",
        "url": "https://www.linkedin.com/in/joyce-tseng-a7115a1aa/"
      }
    ],
    "date": "2022-05-23",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Data Preparation\n2.1 Installing Packages\n2.2 Importing Data\n2.3 Data Wrangling\n\n3. Data Visualization\n3.1 Daily Pattern on\nMonday\n3.2 Daily Pattern on\nTuesday\n3.3 Daily Pattern on\nWednesday\n3.4 Daily Pattern on\nThursday\n3.5 Daily Pattern on\nFriday\n3.6 Daily Pattern on\nSaturday\n3.7 Insight on Everday\nPattern\n3.8 Weekly Pattern on\nSleeping\n3.9 Weekly Pattern on\nEaten\n3.10 Weekly Pattern on\nHunger\n\n\n1. Overview\nIn this take-home exercise, we reveal the daily routine of the most\nhappiness and the less happiness residents in Ohio to see the\ndifferences on their everyday behavior. The data is provided and can be\ndownloaded from VAST\nChallenge 2022. The package of VisiElse is\nthe main method to plot the graph.\n2. Data Preparation\n2.1 Installing Packages\n\n\nShow code\n\npackages = c('tidyverse', 'plotly', 'dplyr', 'data.table', 'lubridate', 'zoo',\n             'ViSiElse', 'scales', 'viridis', 'ggthemes')\n\nfor(p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\n2.2 Importing Data\n\n\nShow code\n\nlog1 <- read_csv(\"ParticipantStatusLogs1.csv\")\nlog2 <- read_csv(\"ParticipantStatusLogs2.csv\")\nparticipants <- read_csv(\"Participants.csv\")\n\n# merge two logs together\ndf <- rbind(log1, log2)\n\n\n\n2.3 Data Wrangling\nPICKING TWO RESIDENTS\nHere we would like to pick two residents who have the highest\n(joviality = 0.999234) and the lowest (joviality = 0.000204) value of\njoviality in Ohio to observe their daily action.\n\n\nShow code\n\n# Get max and min joviality of participants_id\n# slice_max and slice_min is function from the tidyverse\nmax <- participants %>% \n  slice_min(joviality)\nmin <- participants %>% \n  slice_max(joviality)\n\nmax\n\n\n# A tibble: 1 × 7\n  participantId householdSize haveKids   age educationLevel     \n          <dbl>         <dbl> <lgl>    <dbl> <chr>              \n1           758             3 TRUE        56 HighSchoolOrCollege\n# … with 2 more variables: interestGroup <chr>, joviality <dbl>\n\nShow code\n\nmin\n\n\n# A tibble: 1 × 7\n  participantId householdSize haveKids   age educationLevel\n          <dbl>         <dbl> <lgl>    <dbl> <chr>         \n1           113             2 FALSE       51 Graduate      \n# … with 2 more variables: interestGroup <chr>, joviality <dbl>\n\nFILTERING PICKED RESIDENTS\n\n\nShow code\n\n# filter two participants\ndf <- df %>% \n  filter(participantId == \"758\" | participantId == \"131\") \n\n\n\nDERIVING TIME FIELDS\nTo derive time relative data like date, day and hour, we use the\nfunctions from lubridate and zoo to extract\nthem.\n\n\nShow code\n\n# extract date, weekday, hour, minute from timestamp\ndf <- df %>%\n  mutate(date = as.Date(timestamp)) %>%\n  mutate(day = weekdays(date)) %>%\n  mutate(hour = hour(timestamp)) %>%\n  mutate(min = minute(timestamp)) %>%\n  mutate(minutes = hour*60 + min)\n\n\n\nDROPPING UNNEEDED DATA\nThe data in activity logs records participants’ daily behaviour from\n2022-03-01 to 2023-05-31, but we just pick the first week (2022-03-01 to\n2022-03-07) of data to plot in our exercise.\n\n\nShow code\n\ndf <- df %>%\n  filter(date < \"2022-03-08\")\n\n\n\nCREATING WEEKLY DATASETS FOR SLEEP, EATEN AND\nHUNGER\n\n\nShow code\n\n# Weekly sleep data\nsleep <- df %>% \n  select(participantId, date, day, sleepStatus, hour, min, minutes) %>%\n  filter(sleepStatus == \"Sleeping\")\n\n# Weekly eaten data\neaten <- df %>% \n  select(participantId, date, day, hungerStatus, hour, min, minutes) %>%\n  filter(hungerStatus == \"JustAte\")\n\n# Weekly hunger data\nhunger <- df %>% \n  select(participantId, date, day, hungerStatus, hour, min, minutes) %>%\n  filter(hungerStatus == \"Hungry\")\n\n\n\nCREATING DAILY DATASET\n\n\nShow code\n\n# create only Monday data\nMonday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-07\")\n\n# create only Tuesday data\nTuesday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-01\")\n\n# create only Wednesday data\nWednesday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-02\")\n\n# create only Thursday data\nThursday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-03\")\n\n# create only Friday data\nFriday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-04\")\n\n# create only Saturday data\nSaturday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-05\")\n\n# create only Sunday data\nSunday <- df %>% \n  select(participantId, date, day, currentMode, hungerStatus,\n         sleepStatus, hour, min, minutes) %>%\n  filter(date == \"2022-03-06\")\n\n\n\n3. Data Visualization\nIn our dataset, although the daily behavior includes punctual and\nlong action, we would just focus on the start time of all doings. Thus,\nall actions are regarded as short action.\n3.1 Daily Pattern on Monday\nPIVOTTING AND MERGERING THE DATA\n\n\nShow code\n\n# Monday sleep status\nMon_sleep <- Monday %>% \n  group_by(participantId, sleepStatus) %>%\n  dplyr::summarise(value = min(minutes))\n\nMon_sleep <- pivot_wider(Mon_sleep, names_from = sleepStatus, values_from = value)\n\n# Monday hunger status\nMon_hunger <- Monday %>% \n  group_by(participantId, hungerStatus) %>%\n  dplyr::summarise(value = min(minutes))\n  \nMon_hunger <- pivot_wider(Mon_hunger, names_from = hungerStatus, values_from = value)\n\n# Monday mode\nMon_mode <- Monday %>% \n  group_by(participantId, currentMode) %>%\n  dplyr::summarise(value = min(minutes))\n\nMon_mode <- pivot_wider(Mon_mode, names_from = currentMode, values_from = value)\n\n# Merger three behavior\nMon <- merge(x = Mon_sleep, y = Mon_hunger, by = \"participantId\", all = TRUE)\nMon <- merge(x = Mon, y = Mon_mode, by = \"participantId\", all = TRUE)\n\n\n\nARRANGING THE COLUMN ORDER\n\n\nShow code\n\n# rearrange the columns\nMon_order <- c(\"participantId\", \"Sleeping\", \"Awake\", \"BecomingHungry\", \"JustAte\",\n           \"Transport\", \"AtWork\", \"Hungry\", \"AtRestaurant\", \"AtRecreation\", \n           \"AtHome\")\nMon <- Mon[,Mon_order] \n\n\n\nVISUALIZATION\n\n\nShow code\n\n# Monday\ngroup <- c(\"Id: 113\", \"Id: 758\")\nvisi2 <- visielse(Mon,\n                  book = book,\n                  group = group,\n                  method = \"cut\",\n                  tests = F,\n                  pixel = 30,\n                  doplot = F)\nplot(visi2, vp0w = 0.7, unit.tps = \"min\", scal.unit.tps = 30)\n\n\n\n\n3.2 Daily Pattern on Tuesday\nPIVOTTING AND MERGERING THE DATA\n\n\nShow code\n\n# Tuesday sleep status\nTue_sleep <- Tuesday %>% \n  group_by(participantId, sleepStatus) %>%\n  dplyr::summarise(value = min(minutes))\n\nTue_sleep <- pivot_wider(Tue_sleep, names_from = sleepStatus, values_from = value)\n\n# Tuesday hunger status\nTue_hunger <- Tuesday %>% \n  group_by(participantId, hungerStatus) %>%\n  dplyr::summarise(value = min(minutes))\n  \nTue_hunger <- pivot_wider(Tue_hunger, names_from = hungerStatus, values_from = value)\n\n# Tuesday mode\nTue_mode <- Tuesday %>% \n  group_by(participantId, currentMode) %>%\n  dplyr::summarise(value = min(minutes))\n\nTue_mode <- pivot_wider(Tue_mode, names_from = currentMode, values_from = value)\n\n# Merger three behavior\nTue <- merge(x = Tue_sleep, y = Tue_hunger, by = \"participantId\", all = TRUE)\nTue <- merge(x = Tue, y = Tue_mode, by = \"participantId\", all = TRUE)\n\n\n\nARRANGING THE COLUMN ORDER\n\n\nShow code\n\n# rearrange the columns\nTue_order <- c(\"participantId\", \"Sleeping\", \"Awake\", \"BecomingHungry\", \"JustAte\",\n           \"BecameFull\", \"Transport\", \"AtWork\", \"Hungry\", \"AtRestaurant\", \"AtRecreation\", \n           \"AtHome\", \"PrepareToSleep\")\nTue <- Tue[,Tue_order] \n\n\n\nVISUALIZATION\n\n\nShow code\n\n# Tuesday\ngroup <- c(\"Id: 113\", \"Id: 758\")\nvisi3 <- visielse(Tue,\n                  book = book,\n                  group = group,\n                  method = \"cut\",\n                  tests = F,\n                  pixel = 30,\n                  doplot = F)\nplot(visi3, vp0w = 0.7, unit.tps = \"min\", scal.unit.tps = 30)\n\n\n\n\n3.3 Daily Pattern on Wednesday\nPIVOTTING AND MERGERING THE DATA\n\n\nShow code\n\n# Wednesday sleep status\nWed_sleep <- Wednesday %>% \n  group_by(participantId, sleepStatus) %>%\n  dplyr::summarise(value = min(minutes))\n\nWed_sleep <- pivot_wider(Wed_sleep, names_from = sleepStatus, values_from = value)\n\n# Wednesday hunger status\nWed_hunger <- Wednesday %>% \n  group_by(participantId, hungerStatus) %>%\n  dplyr::summarise(value = min(minutes))\n  \nWed_hunger <- pivot_wider(Wed_hunger, names_from = hungerStatus, values_from = value)\n\n# Wednesday mode\nWed_mode <- Wednesday %>% \n  group_by(participantId, currentMode) %>%\n  dplyr::summarise(value = min(minutes))\n\nWed_mode <- pivot_wider(Wed_mode, names_from = currentMode, values_from = value)\n\n# Merger three behavior\nWed <- merge(x = Wed_sleep, y = Wed_hunger, by = \"participantId\", all = TRUE)\nWed <- merge(x = Wed, y = Wed_mode, by = \"participantId\", all = TRUE)\n\n\n\nARRANGING THE COLUMN ORDER\n\n\nShow code\n\n# rearrange the columns\nWed_order <- c(\"participantId\", \"Sleeping\", \"Awake\", \"BecomingHungry\", \"Hungry\", \"JustAte\",\n           \"BecameFull\", \"Transport\", \"AtWork\", \"Hungry\", \"AtRestaurant\", \"AtRecreation\", \n           \"AtHome\", \"PrepareToSleep\")\nWed <- Wed[,Wed_order] \n\n\n\nVISUALIZATION\n\n\nShow code\n\n# Wednesday\ngroup <- c(\"Id: 113\", \"Id: 758\")\nvisi4 <- visielse(Wed,\n                  book = book,\n                  group = group,\n                  method = \"cut\",\n                  tests = F,\n                  pixel = 30,\n                  doplot = F)\nplot(visi4, vp0w = 0.7, unit.tps = \"min\", scal.unit.tps = 30)\n\n\n\n\n3.4 Daily Pattern on Thursday\nPIVOTTING AND MERGERING THE DATA\n\n\nShow code\n\n# Thursday sleep status\nThu_sleep <- Thursday %>% \n  group_by(participantId, sleepStatus) %>%\n  dplyr::summarise(value = min(minutes))\n\nThu_sleep <- pivot_wider(Thu_sleep, names_from = sleepStatus, values_from = value)\n\n# Thursday hunger status\nThu_hunger <- Thursday %>% \n  group_by(participantId, hungerStatus) %>%\n  dplyr::summarise(value = min(minutes))\n  \nThu_hunger <- pivot_wider(Thu_hunger, names_from = hungerStatus, values_from = value)\n\n# Thursday mode\nThu_mode <- Thursday %>% \n  group_by(participantId, currentMode) %>%\n  dplyr::summarise(value = min(minutes))\n\nThu_mode <- pivot_wider(Thu_mode, names_from = currentMode, values_from = value)\n\n# Merger three behavior\nThu <- merge(x = Thu_sleep, y = Thu_hunger, by = \"participantId\", all = TRUE)\nThu <- merge(x = Thu, y = Thu_mode, by = \"participantId\", all = TRUE)\n\n\n\nARRANGING THE COLUMN ORDER\n\n\nShow code\n\n# rearrange the columns\nThu_order <- c(\"participantId\", \"Sleeping\", \"Awake\", \"BecomingHungry\", \"Hungry\", \"JustAte\",\n           \"BecameFull\", \"Transport\", \"AtWork\", \"Hungry\", \"AtRestaurant\", \"AtRecreation\", \n           \"AtHome\", \"PrepareToSleep\")\nThu <- Thu[,Thu_order] \n\n\n\nVISUALIZATION\n\n\nShow code\n\n# Thursday\ngroup <- c(\"Id: 113\", \"Id: 758\")\nvisi5 <- visielse(Thu,\n                  book = book,\n                  group = group,\n                  method = \"cut\",\n                  tests = F,\n                  pixel = 30,\n                  doplot = F)\nplot(visi5, vp0w = 0.7, unit.tps = \"min\", scal.unit.tps = 30)\n\n\n\n\n3.5 Daily Pattern on Friday\nPIVOTTING AND MERGERING THE DATA\n\n\nShow code\n\n# Friday sleep status\nFri_sleep <- Friday %>% \n  group_by(participantId, sleepStatus) %>%\n  dplyr::summarise(value = min(minutes))\n\nFri_sleep <- pivot_wider(Fri_sleep, names_from = sleepStatus, values_from = value)\n\n# Friday hunger status\nFri_hunger <- Friday %>% \n  group_by(participantId, hungerStatus) %>%\n  dplyr::summarise(value = min(minutes))\n  \nFri_hunger <- pivot_wider(Fri_hunger, names_from = hungerStatus, values_from = value)\n\n# Friday mode\nFri_mode <- Friday %>% \n  group_by(participantId, currentMode) %>%\n  dplyr::summarise(value = min(minutes))\n\nFri_mode <- pivot_wider(Fri_mode, names_from = currentMode, values_from = value)\n\n# Merger three behavior\nFri <- merge(x = Fri_sleep, y = Fri_hunger, by = \"participantId\", all = TRUE)\nFri <- merge(x = Fri, y = Fri_mode, by = \"participantId\", all = TRUE)\n\n\n\nARRANGING THE COLUMN ORDER\n\n\nShow code\n\n# rearrange the columns\nFri_order <- c(\"participantId\", \"Sleeping\", \"Awake\", \"BecomingHungry\", \"Hungry\", \"JustAte\",\n           \"BecameFull\", \"Transport\", \"AtWork\", \"Starving\", \"AtRestaurant\", \"AtRecreation\", \n           \"AtHome\", \"PrepareToSleep\")\nFri <- Fri[,Fri_order] \n\n\n\nVISUALIZATION\n\n\nShow code\n\n# Friday\ngroup <- c(\"Id: 113\", \"Id: 758\")\nvisi6 <- visielse(Fri,\n                  book = book,\n                  group = group,\n                  method = \"cut\",\n                  tests = F,\n                  pixel = 30,\n                  doplot = F)\nplot(visi6, vp0w = 0.7, unit.tps = \"min\", scal.unit.tps = 30)\n\n\n\n\n3.6 Daily Pattern on Saturday\nPIVOTTING AND MERGERING THE DATA\n\n\nShow code\n\n# Saturday sleep status\nSat_sleep <- Saturday %>% \n  group_by(participantId, sleepStatus) %>%\n  dplyr::summarise(value = min(minutes))\n\nSat_sleep <- pivot_wider(Sat_sleep, names_from = sleepStatus, values_from = value)\n\n# Saturday hunger status\nSat_hunger <- Saturday %>% \n  group_by(participantId, hungerStatus) %>%\n  dplyr::summarise(value = min(minutes))\n  \nSat_hunger <- pivot_wider(Sat_hunger, names_from = hungerStatus, values_from = value)\n\n# Saturday mode\nSat_mode <- Saturday %>% \n  group_by(participantId, currentMode) %>%\n  dplyr::summarise(value = min(minutes))\n\nSat_mode <- pivot_wider(Sat_mode, names_from = currentMode, values_from = value)\n\n# Merger three behavior\nSat <- merge(x = Sat_sleep, y = Sat_hunger, by = \"participantId\", all = TRUE)\nSat <- merge(x = Sat, y = Sat_mode, by = \"participantId\", all = TRUE)\n\n\n\nARRANGING THE COLUMN ORDER\n\n\nShow code\n\n# rearrange the columns\nSat_order <- c(\"participantId\", \"Sleeping\", \"Awake\", \"BecomingHungry\", \"Hungry\", \"JustAte\",\n           \"BecameFull\", \"Transport\", \"AtWork\", \"Starving\", \"AtRestaurant\", \"AtRecreation\", \n           \"AtHome\", \"PrepareToSleep\")\nSat <- Sat[,Sat_order] \n\n\n\nVISUALIZATION\n\n\nShow code\n\n# Saturday\ngroup <- c(\"Id: 113\", \"Id: 758\")\nvisi7 <- visielse(Sat,\n                  book = book,\n                  group = group,\n                  method = \"cut\",\n                  tests = F,\n                  pixel = 30,\n                  doplot = F)\nplot(visi7, vp0w = 0.7, unit.tps = \"min\", scal.unit.tps = 30)\n\n\n\n\n3.7 Insight on Everday Pattern\nThe order of daily action has been arranged ascendingly a person’s\nnormal one day schedule. We can observe that participant id = 113 and id\n= 758 would go to sleep before 24:00. The awake time on each day for\nthis two people is quite different and even at midnight. It is because\nthat they may wake up to go to the toilet or feel thirsty to drink water\nin the middle of night. Therefore, the awake time sometimes is not in\nthe morning.\nIn addition, it is also can observable that their everyday working\ntime is also fluctuating, meaning that they may arrive and start to work\na bit earlier or later. After leaving their workplace, it is more often\nfor participant id = 758 to go to the restaurant to have a dinner and\nhave recreational activities. This may relates to his low joviality,\nsince he probably needs some ways to release his negative emotion or\npressure.\n3.8 Weekly Pattern on Sleeping\n\n\nShow code\n\ngrouped <- sleep %>% \n  count(day, hour) %>% \n  ungroup() %>%\n  na.omit()\n  \nggplot(grouped, \n       aes(hour, \n           day, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"Sleeping Time\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Weekly Sleeping Time\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nA regular sleeping time can be seen from the graph. There is no\ndifferences wake-up time and sleep time on weekday and weekend.\nNormally, they would go to sleep at around 11pm to 12pm and wake up at\n9am.\n3.9 Weekly Pattern on Eaten\n\n\nShow code\n\ngrouped <- eaten %>% \n  count(day, hour) %>% \n  ungroup() %>%\n  na.omit()\n  \nggplot(grouped, \n       aes(hour, \n           day, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"Eaten Time\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Weekly Eaten Time\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThe eaten time for people each day is quite different, but we can\nobserve that normally they would have 3 meals in one day and prefer\nhaving their lunch a bit late.\n3.10 Weekly Pattern on Hunger\n\n\nShow code\n\ngrouped <- hunger %>% \n  count(day, hour) %>% \n  ungroup() %>%\n  na.omit()\n  \nggplot(grouped, \n       aes(hour, \n           day, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"Hunger Time\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Weekly Hunger Time\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThe graph of pattern on eaten and hunger is more or less\ncomplementary. It can be seen that when there is no record on eaten\ntime, then the color would present in huger graph. For example, during\nmidnight and afternoon.\n\n\n\n",
    "preview": "posts/2022-05-19-takehome4/takehome4_files/figure-html5/unnamed-chunk-17-1.png",
    "last_modified": "2022-08-14T20:31:05+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-05-takehome3/",
    "title": "Take-home Exercise 3",
    "description": "This is my Take-home Exercise on exploring the financial health of Ohio in USA, espically focusing on the prosperity of the businesses there.",
    "author": [
      {
        "name": "Joyce Tseng",
        "url": "https://www.linkedin.com/in/joyce-tseng-a7115a1aa/"
      }
    ],
    "date": "2022-05-14",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Data Preparation\n2.1 Installing Packages\n2.2 Importing the Dataset\n2.3 Data Wrangling and\nExploration\n\n3. Data Visualizations\nand Insights\n3.1\nDistribution of Numbers of Companies on Numbers of Employees\n3.2\nDistribution of Hourly Rate in Prosperous Businesses\n3.3\nDistribution of Hourly Rate by Education Requirement\n3.4\nDistribution of Numbers of Employees by Education Requirement\n\n4. Learing Points\n\n1. Overview\nIn this take-home exercise, we reveal Ohio’s economy and look more in\ndetails on its business prosperity by creating interactive data\nvisualizations with ggplot2 and its extension packages in\nR. The data is provided and can be downloaded from VAST Challenge 2022\nand the topic is about the first point in challenge 3.\n2. Data Preparation\n2.1 Installing Packages\nThe following packages and libraries are installed for this exercise.\nImportant and relative packages for plotting an interactive graph in R\nare:\ntidyverse designs for data science and is used\nextensively for data preparation and wrangling.\nggiraph creates dynamic ggplot graphs with hover and\nclick actions.\nDT provides an R interface to the JavaScript library DataTables that creates interactive\ntable on html page.\npatchwork combines multiple ggplot objects into a\nsingle figure.\ntooltip a column of datasets are displayed when the\nmouse is over responding elements.\n\n\npackages = c('tidyverse', 'readxl', 'knitr', 'dplyr', 'ggplot2', 'ggiraph',\n             'plotly', 'DT', 'patchwork','crosstalk', 'ggridges')\n\nfor(p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\n2.2 Importing the Dataset\nTo reveal Ohio’s financial health, we would only focus on their main\ncommercial businesses, but not including catering industry like\nrestaurants and Pubs. Therefore, the only dataset would be used in this\nexercise is regard to Ohio residents’ Job information. There are 6\nvariables in this dataset, including their working hours, working days,\nhourly rate and education requirement and so on.\n\n\nJobs <- read_csv(\"Datasets/Attributes/Jobs.csv\")\n\n\n\n2.3 Data Wrangling and\nExploration\nDERIVING A NEW COLUMN\nHere we would like to create a new column to view how many employees\nare there in each company. By doing so, we use the mutate() of\ndplyr to generate the frequency by employer_id.\n\n\n# add frequency column\nfinal_data <- final_data %>%\n  group_by(employerId)%>%\n  dplyr::mutate(count=n())\n\n\n\nRENAMING THE COLUMN\nThe default name of using count to derive the above new\ncolumn would call count, which is not intuitive to understand. We would\nlike to change the column name and call it No.Employees.\n\n\n# rename the column\nfinal_data <- final_data %>%\n  rename(c('No.Employees' = 'count'))\n\n\n\nREMOVING USELESS COLUMNS\nThere are some columns that would not be used in our visualization\nlater. To keep the data more clean, we remove some useless columns by\nsubset.\n\n\n# Remove columns\nfinal_data <- subset(final_data, select = -c(daysToWork, buildingType, type))\n\n\n\nCONVERTING DATA TYPE\nSince we would use the deriving columns that we created previously as\nthe category to classify the raw data, we need to convert the data type\nfrom numeric to categorical.\n\n\n# Convert numeric column into categorical\nfinal_data$No.Employees <- as.factor(final_data$No.Employees)\n\n\n\n3. Data Visualizations and\nInsights\n3.1\nDistribution of Numbers of Companies on Numbers of Employees\nGenerally, numbers of employees can be regarded as a company’s\nproductivity. Thus, to identify which business is more popular and\nappears to be more prosperous in Ohio, we would first take a look at\ntheir employees number. Since there are over 500 of businesses in our\ndataset, we use numbers of employees as our category to be the x-axis\nand display which enterprises have hired the most and the least\nworkers.\nTo create an interactive graph, it is not enough to only use\nggplot2 to make it. The bar chart of numbers of companies\non numbers of employees is plotted as follows:\nhighlight_key() is part of plotly package,\nwhich can help us create an object of class\ncrosstalk::SharedData to connect and show corresponding outputs\nof two graphs or a graph with data table.\nhighlight() is also a function of plotly\npackage. It can link to multiple plotly graphs and set various options\nfor brushing them.\nbscols() makes us easily to put HTML elements side by side.\nIn this graph, it is used for connecting the datatable with the bar\nchart.\nThrough the above function, when selecting each whole bar on the\ngraph, the below table would automatically show more details for the\ncorresponding row data.\n\n\ndd <- highlight_key(final_data)\n\ngraph1 <- ggplot(dd, aes(x = No.Employees)) +\n  geom_bar(fill = '#468499') +\n  theme(axis.title.y= element_text(angle=0), axis.ticks.x= element_blank(),\n        panel.background= element_blank(), axis.line= element_line(color= 'grey')) +\n  ggtitle(\"The Distribution of Numbers of Companies on Numbers of Employees\") +\n  xlab(\"Numbers of Employees\") +\n  ylab(\"Count\")\n\ngg <- highlight(ggplotly(graph1),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg, \n                  widths = c(12,12),\n                  DT::datatable(dd,\n                                rownames = FALSE,\n                                colnames = c('Education Requirement' = 'educationRequirement',\n                                             'Employer Id' = 'employerId',\n                                             'Hourly Rate' = 'hourlyRate',\n                                             'Numbers of Employees' = 'No.Employees'), \n                                filter = 'top',\n                                class = 'display'))\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plot, it can be observed:\nBusinesses in Ohio with 8 employees have highest number.\nHighest number of employees in Ohio’s businesses is 9.\n2 is the lowest number of employees in Ohio’s businesses.\n3.2\nDistribution of Hourly Rate in Prosperous Businesses\nIt is not enough to just look at the numbers of labours in a company\nto display its prosperity. Here, we would like to see the distribution\nof hourly rate by numbers of employees and further observe whether\nlarger scale of companies would pay more to their employees. The violin\ngraph is plotted by ploy_ly(), which is a function in\nplotly and is more or less same as ggplotly() to\nconstruct an interacitve graph.\n\n\ngraph2 <- plot_ly(final_data, \n                 x = ~No.Employees, \n                 y = ~hourlyRate,\n                 split = ~No.Employees,\n                 type = 'violin',\n                 box = list(visible = T),\n                 meanline = list(visible = T)) %>%\n  layout(title = \"The Distribution of Hourly Rate in Prosperous Businesses\",\n         xaxis = list(title = 'Numbers of Employees'),\n         yaxis = list(title = 'Hourly Rate'))\n\ngraph2\n\n\n\n\nThe violin plot with boxplot can easily show the distribution of\nhourly rate in each category and disclose some statistical information\nfrom the dataset. The graph indicates:\nThe range of hourly rate is high in company with 5 and 8 employees,\nwith maximum hourly rate up to 100 and minimum around 10.\nThe majority of residents in Ohio earn around 10 to 20 dollars every\nhour.\nThe interquartile range of each category are not obvious, meaning\nthat no matter the scale of businesses the wage of most people do not\nhave much difference.\n3.3\nDistribution of Hourly Rate by Education Requirement\nRidge plot is a good visualization to display the distribution of\ncontinuous value based on a categorical variable. The possible factor to\naffect the hourly rate is education requirement. We would like to see\nwhether higher education level would be granted with more wage.\n\n\nggplot(final_data, \n       aes(x = hourlyRate, y = educationRequirement, fill = factor(stat(quantile)))) + \n  stat_density_ridges(geom = \"density_ridges_gradient\",\n                      calc_ecdf = TRUE,\n                      quantiles = c(0.025, 0.975)) +\n  scale_fill_manual(\n    name = \"Probability\", values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")) +\n  ggtitle(\"The Distribution of Hourly Rate by Education Requirement\") +\n  xlab(\"Hourly Rate\") +\n  theme(axis.title.y = element_blank()) \n\n\n\n\nIt can be observed that people who are graduate surely earn more\nmoney than others. The density of hourly rate in graduate distribution\nis around 20 to 30 dollars; however, others are around or below than 15\ndollars. In addition, its range in 95% of probability distribution is\nmuch wider than other, meaning that most people in this category have\nhigher wage.\n3.4\nDistribution of Numbers of Employees by Education Requirement\nCREATING STATISTICAL DATATABLE\nAfter exploring the distribution of hourly rate by different\neducation requirements, we would like to see more statistical data about\nhourly rate based on education requirement by companies’ size. Hence, we\nclean the needed columns and create a new data table for the following\ngraph.\n\n\n# Create statistical data information\ngraph1_sum <- final_data %>%\n  group_by(No.Employees, educationRequirement) %>%\n  dplyr::summarise(n=n(), mean=mean(hourlyRate), sd=sd(hourlyRate)) %>%\n  mutate(se=sd/sqrt(n-1))\n\n# Convert int column into category\ngraph1_sum$No.Employees <- as.factor(graph1_sum$No.Employees)\n\n# Round off to two decimals\ngraph1_sum$mean <- round(graph1_sum$mean, digit = 2) \ngraph1_sum$se <- round(graph1_sum$se, digit = 2) \ngraph1_sum$sd <- round(graph1_sum$sd, digit = 2) \n\n\n\nPLOTTING THE GRAPH\nThe bar graph displays the percentage of different education\nrequirement roles by companies’ size. Moreover, it is connected to the\nbelow data table and can select a bar to see the corresponding data.\n\n\nd1 <- highlight_key(graph1_sum)\n\nfinal_data$tooltip <- c(paste0(\n  \"No. Employees:\", final_data$No.Employees,\n  \"Percentage: \", final_data$n,\n  \"Eduction: \", final_data$educationRequirement))\n\ngraph3 <- ggplot(d1, aes(x = No.Employees, y = n, fill = educationRequirement)) +\n  geom_bar(position=\"fill\", stat=\"identity\") +\n  theme(legend.position=\"top\") +\n  ggtitle(\"Numbers of Employess by Education Requirement\") +\n  xlab(\"Numbers of Employees\") +\n  ylab(\"Percentage\\n(%)\")\n\n\ngg3 <- highlight(ggplotly(graph3, tooltip = final_data$tooltip),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg3, \n                  widths = c(12,12),\n                  DT::datatable(d1,\n                                rownames = FALSE,\n                                colnames = c('Numbers of Employees' = 'No.Employees',\n                                             'Education Requirement' = 'educationRequirement',\n                                             'N' = 'n',\n                                             'Average Hourly Rate' = 'mean',\n                                             'Hourly Rate Std' = 'sd', \n                                             'Hourly Rate SE' = 'se'),\n                                class = 'display'))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are some intereting findings in this interactive graph:\nThe average hourly rate in graduate is higher than other education\nlevel roles.\nThe differences of average hourly rate is small between people\ngraduating from high school or college and with low education\nlevel.\nThe value of standard deviation in hourly rate for people with\nhigher education level would become greater, implying that the education\nlevel is not the only way to decide a person’s wage.\n4. Learing Points\nThis take-home exercise helps us to hone our skills to design a good\nvisualization for other people to use. Furthermore, it also makes me\nmore understand the usage of different packages in R for plotting a\ngraph, especially ggplot2 with ggirafe and\nggplotly.\nMy key takeaways are:\nAdding interactivity is like a auxiliary tool for us to tell more\nstories in a graph; however, it is not always a must. It is possible to\nbe an additional function for people to use or even bother them to read\nfrom the visualization. Thus, we need to think about the purpose for our\nvisualization design.\nThere are many packages can help us build an interactive plot in\nR, but some of them cannot use together and even would affect another\nexecution. We should always plan first before starting to write down the\ncode so that we can select the correct package to create what we\nexpect.\n\n\n\n",
    "preview": "posts/2022-05-05-takehome3/takehome3_files/figure-html5/unnamed-chunk-12-1.png",
    "last_modified": "2022-08-14T20:31:05+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-26-takehome2/",
    "title": "Take-home Exercise 2",
    "description": "This is my Take-home Exercise for critiquing and remaking the data visualization in terms of clarity and aesthetics on graphs.",
    "author": [
      {
        "name": "Joyce Tseng",
        "url": "https://www.linkedin.com/in/joyce-tseng-a7115a1aa/"
      }
    ],
    "date": "2022-05-02",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Critique\n2.1 Clarity\n2.2 Aesthetics\n\n3. Data Preparation\n4. Redesigned Visualization\n4.1 Step-by-Step\nDescription\n\n5. Quick Look for\nRemade Visualization\n5. Learning Points\n\n1. Overview\nIn this exercise, we will critique the following distribution from a\npeer in terms of graph’s clarity and aesthetics, and will remake the\noriginal design based on the data visualization principles and best\npractice.\n\n2. Critique\n2.1 Clarity\nChart Title is not helpful; absence of lead-in and\ncall-outs\nThe title of above 6 plots does not explain the context of the\nvisualization. Readers would not know the key message that the graph\nwould like to convey. For example, the title “Distribution of Age” on\nfirst graph, it does not point out what does the number of distribution\non age present for. Moreover, there are also no lead-in and call-outs to\nexplain any trend or insights.\nArrangement of categorical variables\nOn graph 2, the arrangement of education level is not readable\nfor users in jumbled order.\nOn graph 4, the x-axis is arranged based on numbers of\nparticipants in descending order. However, it is not intuitive for\nreaders with the false group appearing on the left, followed by the true\ngroup. This is quite confusing for readers who expect a logical order of\nx-axis.\n\nChart Type in Appropriate\nDensity plots are useful to quickly visualize the distribution of\nimbalanced dataset by smoothing out the noise and displaying the peak\nand good to compare the distribution of two datasets. For graph 5, the\ndistribution is quite flat, which would be hard to detect highest\ndensity at first glance.\nviolin plots are used for comparing multiple data distribution\nsince they are placed side by side. However, the statistical\ndistribution of each category such as mean and medium cannot be observed\nfrom it. For instance, readers can only witness that there is less\nnumber from house size 1 with 0.75 joviality among three but cannot know\nthe position of statistical values.\n\n2.2 Aesthetics\nTick marks are necessary on continuous scale\nTick marks are missing for continuous data on graph 1 and 5. They are\nused to indicate a reference value at a given point in a chart and\nensure the number of tick marks between each labeled tick marks is\nsame.\nLack of data-ink and annotations\nThe above 6 charts are all used the same color without data-ink or\nany annotations, which is difficult for readers to identify the message\nintending to deliver from each graph.\nX-axis and Y-axis Title\nThe title of x-axis and y-axis should be consistent with a start of\nuppercase letters or lowercase letters.\n3. Data Preparation\nThe data preparation step here is to load the data and visualization\nfrom the original author, which is not the main focus on the exercise,\nso I would not go into details for this and just for reference.\nInstalling Packages\n\n\nhide\n\npackages <- c('tidyverse','ggdist','gghalves','ggthemes','hrbrthemes','ggridges','patchwork','wesanderson')\nfor(p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\nImporting Data\n\n\nhide\n\nparticipants_data <- read_csv(\"Datasets/Attributes/Participants.csv\")\n\n\n\n\n\nhide\n\nsaveRDS(participants_data, file = \"participants_data.rds\")\n\n\n\n\n\nhide\n\nparticipants_data <- readRDS(file = \"participants_data.rds\")\n\n\n\n4. Redesigned Visualization\n4.1 Step-by-Step Description\nGraph 1 - Original\n\n\nhide\n\nbefore1 <- ggplot(data=participants_data,\n       aes(x = age)) +\n  geom_histogram(bins=20,\n                 color = \"grey25\",\n                 fill = \"light blue\")+\n  ggtitle(\"Distribution of Age\")+\n  ylab(\"No. of\\nParticipants\") +\n  theme_ipsum(axis_title_size = 12,\n              grid =\"Y\") +\n  theme(axis.title.y = element_text(angle=0))+\n  geom_vline(aes(xintercept=mean(age,na.rm=T)),\n              color=\"red\",\n              linetype=\"dashed\",\n              size=1) +\n  geom_vline(aes(xintercept=median(age,na.rm=T)),\n              color=\"grey30\",\n              linetype=\"dashed\",\n              size=1)+\n  geom_text((aes(x= mean(age,na.rm=T)+1,\n                 label=\"mean\",\n                 y = 75,\n                 angle =90)),\n            color= \"red\")+\n  geom_text((aes(x= median(age,na.rm=T)-1,\n                 label=\"median\",\n                 y = 75,\n                 angle =90)),\n            color = \"grey30\")\nprint(before1)\n\n\n\n\nGraph 1 - Remake\n\n\nhide\n\nafter1 <- ggplot(data=participants_data,\n       aes(x = age)) +\n  geom_histogram(bins=20,\n                 color = \"grey20\",\n                 fill = \"lightblue3\", size=0.4)+\n  ggtitle(label= \"Distribution of Participants' Age\",\n          subtitle= \"The proportion of 30 to 40 age groups account for the most in Ohio's population\")+\n  xlab(\"Age\")+\n  ylab(\"Number of\\nParticipants\") +\n  theme(axis.title.y = element_text(angle=0))+\n  geom_vline(aes(xintercept=mean(age,na.rm=T)),\n              color=\"red\",\n              linetype=\"dashed\",\n              size=.6) +\n  geom_vline(aes(xintercept=median(age,na.rm=T)),\n              color=\"darkblue\",\n              linetype=\"dashed\",\n              size=.6)+\n  geom_text((aes(x= mean(age,na.rm=T)+1,\n                 label=\"mean\",\n                 y = 75,\n                 angle =90)),\n            color= \"red\")+\n  geom_text((aes(x= median(age,na.rm=T)-1,\n                 label=\"median\",\n                 y = 75,\n                 angle =90)),\n            color = \"darkblue\")+\n  scale_x_continuous(breaks=seq(20,60,5))+\n  scale_y_continuous(breaks=seq(0,85,20))+\n  theme(axis.title.y= element_text(angle=0),\n        plot.title = element_text(color=\"black\", size=16, face=\"bold.italic\"),\n        plot.subtitle = element_text(size=10),\n        panel.background= element_blank(), \n        axis.line= element_line(color= 'grey'), \n        panel.grid.major.y = element_line(size = 0.3, \n                                          linetype = 'solid', colour = \"grey\"), \n        panel.grid.minor.y = element_line(size = 0.1, \n                                          linetype = 'solid', colour = \"grey\")) \n\nprint(after1)  \n\n\n\n\nImprovements are made on a few elements:\nMinor grid line is added on the y-axis, which helps reader know\nthe exact value for each bar and compare for different groups.\nSubtitle is updated to indicate the insight from graph and help\nreader understand the message behind.\nTick marks is added on x-axis and y-axis. This is necessary for\ncontinuous variables to point out the corresponding values to each\nbar.\nGraph 2 - Original\n\n\nhide\n\nlevel_order <- c('Low','HighSchoolOrCollege','Bachelors','Graduate')\nbefore2 <- ggplot(data=participants_data,\n      aes(x=factor(educationLevel,levels = level_order)))+\n  geom_bar(color = \"grey25\",\n           fill=\"light blue\") +\n  coord_flip() +\n  ylab(\"No of Participants\") +\n  xlab(\"Education Level\") +\n  theme_ipsum(axis_title_size = 12, grid =\"X\")+\n  theme(axis.title.y=element_text(angle =0,\n                                  margin=margin(r=-70)),\n        axis.line.x = element_line(color=\"grey25\", size = 0.02)) +\n  geom_text(stat=\"count\",\n    aes(label=paste0(..count..,\", \",\n    round(..count../sum(..count..)*100,\n      1),\"%\")),\n    hjust=1,\n    color = \"grey25\",\n    size=3.5)+\n  ggtitle(\"Distribution of Education\")\n\nprint(before2)\n\n\n\n\nGraph 2 - Remake\n\n\nhide\n\nafter2 <- ggplot(data=participants_data,\n      aes(x=reorder(educationLevel,educationLevel,function(x)length(x))))+\n  geom_bar(fill=\"light blue3\") +\n  coord_flip() +\n  ylab(\"Number of Participants\") +\n  xlab(\"Education Level\") +\n  theme(axis.title.y=element_text(angle =0,\n                                  margin=margin(r=-70)),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.minor.x = element_blank()) +\n  geom_text(stat=\"count\",\n    aes(label=paste0(..count..,\", \",\n    round(..count../sum(..count..)*100,\n      1),\"%\")),\n    hjust=1.08,\n    color = \"grey30\") +\n  theme(axis.title.y= element_text(angle=0),\n        plot.title = element_text(color=\"black\", size=16, face=\"bold.italic\"),\n        plot.subtitle = element_text(size=10),\n        panel.background= element_blank(), \n        axis.line= element_line(color= 'grey'), \n        panel.grid.major.x = element_line(size = 0.3, \n                                          linetype = 'solid', colour = \"grey\"), \n        panel.grid.minor.x = element_line(size = 0.1, \n                                          linetype = 'solid', colour = \"grey\"),\n        axis.ticks.y = element_blank()) +\n  ggtitle(label= \"Distribution of Participants' Education Level\",\n          subtitle= \"Most people in Ohio enter the workplace after graduating from high school or college\")\n\nprint(after2)\n\n\n\n\nImprovements are made on a few elements:\nThe order of education level on y-axis is reorder in descending\norder. This format is more clear and readable to find out the lowest and\nhighest value on graph.\nThe label on bars has been adjusted and moved a little to left so\nthat the icon of % won’t cling to the border of bars.\nGraph 3 - Original\n\n\nhide\n\nbefore3 <- ggplot(data=participants_data,\n      aes(x=householdSize))+\n  geom_bar(color = \"grey25\",\n           fill=\"light blue\") +\n  ylab(\"No of\\nParticipants\") +\n  xlab(\"Household Size\") +\n  ylim(0,400) +\n  theme_ipsum(axis_title_size = 12, grid =\"Y\")+\n  theme(axis.title.y=element_text(angle =0,\n                                  margin=margin(r=20))) +\n  geom_text(stat=\"count\",\n    aes(label=paste0(..count..,\", \",\n    round(..count../sum(..count..)*100,\n      1),\"%\")),\n    vjust=-0.5,\n    color = \"grey25\",\n    size=3.5)+\n  ggtitle(\"Distribution of Household Size\")\n\nprint(before3)\n\n\n\n\nGraph 3 - Remake\n\n\nhide\n\nafter3 <- ggplot(data=participants_data,\n      aes(x=householdSize))+\n  geom_bar(fill=\"light blue3\") +\n  ylab(\"Number of\\nParticipants\") +\n  xlab(\"Household Size\") +\n  ylim(0,400)+\n  ggtitle(label= \"Distribution of Participants' Household Size\",\n          subtitle= \"Around 70% of participants are married, but most of them do not have kids in familiy\") +\n  theme(axis.title.y= element_text(angle=0,\n                                  margin=margin(r=20)),\n        panel.background= element_blank(),\n        plot.title = element_text(color=\"black\", size=16, face=\"bold.italic\"),\n        plot.subtitle = element_text(size=10), \n        axis.line= element_line(color= 'grey'), \n        panel.grid.major.y = element_line(size = 0.3, \n                                          linetype = 'solid', colour = \"grey\"), \n        panel.grid.minor.y = element_line(size = 0.1, \n                                          linetype = 'solid', colour = \"grey\"),\n        axis.ticks.x = element_blank())+\n  geom_text(stat=\"count\",\n    aes(label=paste0(..count..,\", \",\n    round(..count../sum(..count..)*100,\n      1),\"%\")),\n    vjust=-0.5,\n    color = \"grey25\",\n    size=3.5)\n\nprint(after3)\n\n\n\n\nImprovements are made on a few elements:\nWithout the border line on bars, the overall layout and design is\nmore neat and concise.\nAdding minor grid line can accurately know the value on each bar\nwithout labels on it.\nThe title is renamed to be more specific.\nGraph 4 - Original\n\n\nhide\n\nbefore4 <- ggplot(data=participants_data,\n      aes(x=haveKids))+\n  geom_bar(color = \"grey25\",\n           fill=\"light blue\") +\n  ylab(\"No of\\nParticipants\") +\n  xlab(\"Have Kids\") +\n  ylim(0,750) +\n  theme_ipsum(axis_title_size = 12, grid =\"Y\")+\n  theme(axis.title.y=element_text(angle =0,\n                                  margin=margin(r=20))) +\n  geom_text(stat=\"count\",\n    aes(label=paste0(..count..,\", \",\n    round(..count../sum(..count..)*100,\n      1),\"%\")),\n    vjust=-0.5,\n    color = \"grey25\",\n    size=3.5)+\n  ggtitle(\"Participants with and without kids\")\nprint(before4)\n\n\n\n\nGraph 4 - Remake\n\n\nhide\n\nparticipants_data <- within(participants_data, \n                   haveKids <- factor(haveKids, \n                                      levels=names(sort(table(haveKids), \n                                                        decreasing=FALSE))))\n\nafter4 <- ggplot(data=participants_data, aes(x=haveKids))+\n  geom_bar(fill=\"light blue3\", width = 0.7) +\n  ylab(\"Number of\\nParticipants\") +\n  xlab(\"Have Kids\") +\n  theme(axis.title.y=element_text(angle =0,\n                                  margin=margin(r=20))) +\n  geom_text(stat=\"count\",\n    aes(label=paste0(..count..,\", \",\n    round(..count../sum(..count..)*100,\n      1),\"%\")),\n    color = \"grey25\",\n    hjust=0.5,\n    vjust=-0.3)+\n  ggtitle(label = \"Dsitribution of Participants with and without kids\",\n          subtitle = \"Most family do not have kids in Ohio, even though the majority are married\")+\n  scale_y_continuous(breaks=seq(0,1200,150))+\n  theme(axis.title.y= element_text(angle=0),\n        plot.title = element_text(color=\"black\", size=16, face=\"bold.italic\"),\n        plot.subtitle = element_text(size=10),\n        panel.background= element_blank(), \n        axis.line= element_line(color= 'grey'), \n        panel.grid.major.y = element_line(size = 0.3, \n                                          linetype = 'solid', colour = \"grey\"), \n        panel.grid.minor.y = element_line(size = 0.1, \n                                          linetype = 'solid', colour = \"grey\"),\n        axis.ticks.x = element_blank()) \nprint(after4)\n\n\n\n\nImprovements are made on a few elements:\nAdjusting the order of x-axis in logical way.\nRemoving the border line on bars for clear\nvisualization.\nGraph 5 - Original\n\n\nhide\n\nbefore5 <- ggplot(participants_data,\n       aes(x=joviality))+\n  geom_density(color = \"grey25\",\n               fill=\"light Blue\")+\n  ggtitle(\"Distribution of Joviality\")+\n  theme_ipsum(axis_title_size = 12, grid=\"Y\")+\n  theme(axis.title.y = element_text(angle=0))+\n  scale_y_continuous(expand = c(0,0),limits = c(0,1.5))\n\nprint(before5)\n\n\n\n\nGraph 5 - Remake\n\n\nhide\n\nafter5 <- ggplot(participants_data, \n       aes(joviality)) +\n  geom_histogram(bins=20,\n                 color = \"grey20\",\n                 fill = \"white\", size=0.4) +\n  geom_density(aes(y= ..density..*60), lwd = 1, colour =\"lightblue3\",\n               fill = \"lightblue3\", alpha = 0.6) +\n  scale_y_continuous('Number of\\nResidents',\n                     expand = c(0.05, 0.2),\n                     sec.axis = sec_axis(~. /60, name= 'Density',\n                                         breaks= seq(0, 1.2, 0.5) )) +\n  geom_vline(aes(xintercept=mean(joviality)),\n            color=\"red\", linetype=\"dashed\", size=.6)+\n  geom_vline(aes(xintercept=median(joviality)),\n            color=\"darkblue\", linetype=\"dashed\", size=.6) +\n  labs(y= 'Number of\\nResidents', x= 'Joviality') +\n  ggtitle(label= \"Distribution of Residents' Joviality\",\n       subtitle= 'Numbers of residents in Ohio with happiness or not distribute evenly') +\n  theme(axis.title.y= element_text(angle=0), \n        axis.title.y.right = element_text(angle=0, vjust = 1),\n        panel.grid.major = element_line(color= 'grey', size = 0.1),\n        panel.background= element_blank(), \n        axis.line= element_line(color= 'grey'),\n        plot.title = element_text(color=\"black\", size=16, face=\"bold.italic\"),\n        plot.subtitle = element_text(size=10))\n\nprint(after5)\n\n\n\n\nImprovements are made on a few elements:\nHistogram is added on the visualization because it is difficult\nfor reader to identify the value for different level of joviality. From\nthe density graph we can conclude that there are two local peaks on the\ndistribution, one around joviality = 0.15-0.30 and another around\n0.85-0.90, while the highest value is on 0.90-0.95.\nMean and median joviality value is presented on the graph to\nprovide additional statistical information on the distribution.\nGraph 6 - Original\n\n\nhide\n\nbefore6 <- ggplot(data = participants_data,\n  aes(y = joviality,\n  x= factor(householdSize))) +\n  geom_violin(color =\"grey25\",\n              fill=\"light blue\") +\n  xlab(\"Household Size\")+\n  ylab(\"Joviality\")+\n  theme_ipsum(axis_title_size=12, grid =\"Y\")+\n  theme(axis.title.y = element_text(angle=0))+\n  ggtitle(\"Joviality index by Household size\")\nprint(before6)\n\n\n\n\nGraph 6 - Remake\n\n\nhide\n\nafter6 <- ggplot(data = participants_data,\n  aes(y = joviality,\n  x= factor(householdSize))) +\n  geom_violin(width=.75, colour =\"lightblue3\",\n               fill = \"lightblue3\", alpha = 0.6) +\n  xlab(\"Household Size\")+\n  ylab(\"Joviality\")+\n  theme(axis.title.y = element_text(angle=0))+\n  ggtitle(label = \"Distribution of Joviality index by Household size\",\n          subtitle = \"The average of happiness index in Ohio is 0.5 among all household size\") +\n  geom_boxplot(width=0.1, color=\"black\", fill=\"white\") +\n  stat_summary(geom = \"point\",\n               fun.y=\"mean\",\n               colour =\"red\",\n               size=2)+\n  theme(axis.title.y= element_text(angle=0),\n        panel.background= element_blank(), \n        axis.line.y = element_line(color= 'grey'),\n        plot.title = element_text(color=\"black\", size=16, face=\"bold.italic\"),\n        plot.subtitle = element_text(size=10), \n        panel.grid.major.y = element_line(size = 0.3, \n                                          linetype = 'solid', colour = \"grey\"), \n        panel.grid.minor.y = element_line(size = 0.1, \n                                          linetype = 'solid', colour = \"grey\"),\n        axis.ticks.x = element_blank()) \n\nprint(after6)\n\n\n\n\nImprovements are made on a few elements:\nBoxplot is added on the remade graph to show the detailed\ndistribution of joviality on different household size.\nThe mean value of joviality is marked on the redesigned plot to\nindicate the differences of joviality index from each household\nsize.\n5. Quick Look for Remade\nVisualization\n\n\nhide\n\npatchwork <- (after1 + after2)/(after3 + after4)/(after5 + after6)\npatchwork + plot_annotation(\n  title = \"Demographics of Engagement, Ohio, USA\",\n  subtitle = \"The below plots reveal the Demographics of the city\",\n  theme = theme(plot.title = element_text(size = 22, face=\"bold\"),\n                plot.background = element_rect(fill = NA,\n                                               colour = 'black',\n                                               size = 1),\n                plot.margin = margin(2,2,1,1,\"cm\"))\n)\n\n\n\n\n5. Learning Points\nThe purpose of this take-home exercise is to learn from peers and\nimprove our expression on plots. This drives me to reflect what I have\ndone on take-home exercise 1 after viewing all visualization design from\ndifferent perspectives of my classmates.\nMy key takeaways are:\nThere is not just a fixed way to plot a graph or design the\nvisualization for our story. It is always good if plots can deliver\nclear message and have aesthetics there.\nIt is not limited to just use one graph for the visualization.\nThe design of each type of graph has their own characteristics and\nspecific scenarios to use, but sometimes it is not enough to provide the\ninformation on single chart. Adding or combining properly other type of\ngraphs in one data visualization could definitely help readers to get\nyour points in short time.\n\n\n\n",
    "preview": "posts/2022-04-26-takehome2/takehome2_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2022-08-14T20:31:04+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-18-takehome1/",
    "title": "Take-home Exercise 1",
    "description": "This is my Take-home Exercise on exploring demographic of Ohio in USA from VAST Challenge 2022.",
    "author": [
      {
        "name": "Joyce Tseng",
        "url": "https://www.linkedin.com/in/joyce-tseng-a7115a1aa/"
      }
    ],
    "date": "2022-04-20",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Data Preparation\n2.1 Challenges Faced\n2.2 Ways to Overcome\nChallenges\n\n3. Sketch\n4. Step-by-step Description\n4.1 Installing Packages\n4.2 Importing the Dataset\n4.3 Data Wrangling\n4.4 Plot Population\nProportion\n4.5 Plot Education Level\n4.6 Plot Education\nLevel on Different Age\n4.7 Plot the\nMedium of Income by Eduction Level\n4.8 Plot the\nIncome on Age by Eduction Level\n4.9 Insight from\nVisualization\n\n5. Learning Points\n\n1. Overview\nIn this take-home exercise, we will explore and reveal the\ndemographics of Ohio in USA by creating data visualizations with\nggplot2 in R. The data is provided and can be downloaded\nfrom VAST Challenge\n2022. The data visualizations included in this exercise are:\nA population proportion of kids and adults.\nNumbers of education levels in 4 categories: Low, High School or\nCollege, Bachelors and Graduate.\nNumbers of education levels on different age.\nA medium of wage on education levels.\nA distribution of wage on age by education levels.\n2. Data Preparation\n2.1 Challenges Faced\nThe raw data only reveals a boolean value that whether the surveyed\nvolunteers have kids or not without further detailed information such as\ntheir kids’ age for us to identify the population composition.\nThe data of participants’ income contains different timestamp record\nand is also inconsistent between each participants.\nThe default visualization of size order created by\nggplot2 is based on the alphabetical order of categories in\nthe column.\n2.2 Ways to Overcome\nChallenges\nThe legal age of an adult is 18 years old generally in US;\ntherefore, the definition of a kid is a person who is under 18.\nAccording to Forbes\nstudy, the average of first-time mother in USA is from 21 to 26,\nwhile for fathers, it is from 27 to 31. Given this, we can defer that\ntheir kids are already an adult for those participants aged over\n50.\nThe function of summarize() in dplyr package\ncan help us summarize each group to fewer rows. Thus, we can derive the\naverage income of each participants from different timestamp.\nThe relevel() function in R can help us to resort the\nlevels of a factor by sepcifying our expected order on the grouping\nvariables.\n3. Sketch\n\n4. Step-by-step Description\n4.1 Installing Packages\nA list of packages, namely tidyverse,\nplotly, readxl, knitr,\ndplyr, ggplot2, grid would be\nused in this exercise. This code chunk installs the required packages\nand loads them into RStudio environment.\n\n\npackages = c('tidyverse', 'plotly', 'readxl', 'knitr', 'dplyr', 'ggplot2', \n             'grid')\n\nfor(p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}\n\n\n\n4.2 Importing the Dataset\nData import was accomplished using read_csv() of readxl package,\nwhich is useful for reading csv files into a tibble.\n\n\nparticipants <- read_csv(\"Datasets/Attributes/Participants.csv\")\nFinancialJournal <- read_csv(\"Datasets/Journals/FinancialJournal.csv\")\n\n# Inspecting the structure of every columns in the dataframe\nglimpse(participants)\nglimpse(FinancialJournal)\n\n\n\n4.3 Data Wrangling\nDERIVING NUMBERS OF KIDS AND ADULTS\nTo derive new columns from the existing columns, the\nmutate() of dplyr is used to generate the data\nwith condition function, if_els().\n\n\nparticipants_mutated <- participants %>%\n  mutate(kids = if_else(haveKids == TRUE & age < 50, householdSize - 2, 0)) %>%\n  mutate(adults = if_else(haveKids == TRUE & age < 50, 0, householdSize))\n\n\n\nMERGING THE TWO DATA FRAMES\nBefore combining the separate data frames, the join table is created\nfirst and has calculated the average wage of each participants by\nparticipant ID. The merge() of dplyr is used\nto add a new column, wage, on the original data frame.\n\n\nWage <- FinancialJournal %>%\n  filter(category == \"Wage\") %>%\n  group_by(participantId) %>%\n  select(participantId, amount) %>%\n  summarise(wage = mean(amount))\n\nparticipants_mutated <- merge(x = participants_mutated, \n                              y = Wage[ , c(\"participantId\", \"wage\")], \n                              by = \"participantId\", all.x = TRUE)\n\n\n\n\n\n\n4.4 Plot Population Proportion\nPIVOTTING DATA\nThe column of kids and adults in original data frame are two separate\ncolumns and shows the value of each. This is not a good data structure\nfor ggplot2 to produce the graph, so we use\ngather() function to pivot them into a better structure.\n\n\nPopulation <- participants_mutated %>%\n  select(kids, adults) %>%\n  summarise(kids = sum(kids), adults = sum(adults)) \n\nPopulation <- gather(Population, kids, adults, key = group, value = value)\n\n\n\n\n\n\n\n\n\nPLOTTING THE GRAPH\nTo look at the demographics of a city, the population composition is\nthe first thing that we would like to know and the pie chart is the\nsuitable one to plot, which is mainly used for displaying the proportion\nin a variable.\nA graph was plotted using ggplot2 as follows:\ngeom_label is used to show the value of each group.\ngeom_text is used to display and calculate the percentage\nof each group.\n\n\nggplot(Population, aes(x=\"\", y=value, fill=group)) +\n  geom_bar(stat=\"identity\", width=1, color=\"white\") +\n  coord_polar(\"y\", start=0) +\n  theme_void() +\n  geom_label(aes(label = value), \n             position = position_stack(vjust = 0.5), \n             show.legend = FALSE) +\n  geom_text(aes(label = paste(round(value / sum(value) * 100, 1), \"%\"), x = 1.3), \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer() +\n  ggtitle(\"Population Composition in Ohio USA\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n4.5 Plot Education Level\nAfter having a quick look at the population, another important factor\nin demographics is people’s education level. The bar graph is to show\nthe difference and the number of people in each category in a descending\norder.\nA graph was plotted using ggplot2 as follows:\nreorder() is to sort the bars by their respective\nfrequencies for better comparison.\ngeom_text() is to show the information of their value and\npercentage.\n\n\nggplot(participants_mutated, aes(x=reorder(educationLevel, \n                                           educationLevel, \n                                           function(x)-length(x)))) +\n  geom_bar(fill = \"lightsteelblue1\") +\n  ylim(0, 580) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100, 1), \"%\")), vjust=-1) +\n  ylab(\"No. of\\nParticipants\") +\n  theme(axis.title.y=element_text(angle = 0)) +\n  ggtitle(\"Population Distribution on Education Level\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  theme(axis.title.x=element_blank())\n\n\n\n\n4.6 Plot Education Level\non Different Age\nWe would like to see further that the distribution of people in\ndifferent age in each education level, we also put the background data\nthat sums up the number of people in different age.\nA graph was plotted using ggplot2 as follows:\nfactor() of Base R function can help resort the levels of a\nfactor by our expected order.\nCreating the data_bg is to reveal the distribution of age\nby education level with reference to all participants.\nfacet_wrap() is created to display numbers of people by a\ndiscrete variable, education level, on different age.\n\n\nparticipants_mutated$educationLevel = \n  factor(participants_mutated$educationLevel,\n         levels=c('Low','HighSchoolOrCollege','Bachelors','Graduate'))\n\ndata <- participants_mutated\ndata_bg <- data[, -5]\n\nggplot(data, aes(x = age, fill = educationLevel)) +\n  geom_histogram(data = data_bg, fill = \"grey\", alpha = .5) + \n  geom_histogram(colour = \"white\") +\n  facet_wrap(.~ educationLevel) +\n  guides(fill = FALSE) +  \n  theme_bw() +\n  theme(strip.background = element_rect(fill=\"beige\")) +\n  xlab(\"Age\") +\n  theme(axis.title.x = element_text(angle = 0)) +\n  theme(axis.title.y = element_blank()) +\n  ggtitle(\"Numbers of People in Different Age in Each Education Level\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n4.7 Plot the Medium\nof Income by Eduction Level\nThe boxplot is a way to compare multiple data distributions, since\nthey can be placed side by side by a discrete variable. Here we would\nlike use box plot to see the financial conditions of each participants\nby education level.\nA graph was plotted using ggplot2 as follows:\nThe medium value is added by using the geom_() function\nwith stat=summary and respective function in\nfun.y.\n\n\nggplot(data, aes(x = educationLevel, y = wage)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",\n             fun.y=\"medium\",\n             colour =\"red\",\n             size = 1.5) +\n  ylab(\"Wage\\n(USD)\") +\n  theme(axis.title.y=element_text(angle = 0)) +\n  theme(axis.title.x=element_blank())  +\n  ggtitle(\"The Medium of Income by Education Level\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n4.8 Plot the Income on\nAge by Eduction Level\nSince the age is also a factor to affect one’s income, we use the\nscatterplot to present, helping us easily observe the value of each\npoint in two axes.\nA graph was plotted using ggplot2 as follows:\nfacet_grid() instead of facet_wrap() is to better\ncompare the value from discrete variables on the matrix of panels in one\nrow.\n\n\nggplot(participants_mutated,\n       aes(x = age, y = wage, colour = factor(educationLevel))) +\n  geom_point(size = 1) + \n  facet_grid(.~ educationLevel, scales = \"free\") +\n  theme(strip.background = element_rect(fill=\"beige\"))  +\n  guides(colour = FALSE) +\n  xlab(\"Age\") +\n  theme(axis.title.x = element_text(angle = 0)) +\n  ylab(\"Wage\\n(USD)\") +\n  theme(axis.title.y=element_text(angle = 0)) +\n  ggtitle(\"Numbers of People in Different Age in Each Education Level\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n4.9 Insight from Visualization\nFrom the plot, we can describe that the education level in Ohio is\nhigh. Almost 40% of people graduated from bachelor and even higher and\nover 50% of people go to work after studying in high school and college.\nIn general, higher education level would result in higher income. The\nboxplot above has verified this and delivers the same information. The\nvalue of medium becomes higher from high school or college to graduate.\nAlthough the medium of low education level is higher than others, the\npercentage is too small (less than 10%) and the spread of wage is large.\nWe would not say people would have higher income if only in low\neducation level. However, the scatterplot tells us that the income for\nthe majority of people are under 250 dollars no matter the education\nlevel. Therefore, we can obtain that those whose income are over 250\ndollars in Ohio belongs to higher class.\n5. Learning Points\nThis take-home exercise provides a great opportunity to get\nfamiliarized with how to clean data and make the visualization by R\npackages, especially using tidyverse and\nggplot2 and their extensions.\nMy key takeaways are:\nAlways plan first before writing the code. A good visualization does\nnot just plot a graph and mark the label there but also the information\nbehind. This is a kind of storytelling for the audience to understand\nwhat you would like to deliver from the graph. To convince others of our\nfindings, a logical plan is necessary!\nRemember the principle of ‘Garbage in, garbage out.’ This means that\na data preparation for needed variables must be done properly before\nclear and meaningful visualizations are built no matter using R, Python\nor Tableau.\n\n\n\n",
    "preview": "posts/2022-04-18-takehome1/takehome1_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2022-08-14T20:31:04+08:00",
    "input_file": {}
  }
]
